---
title: "Economic Modelling for Political Analysis"
subtitle: "Volume I: Economic Game Theory"
author: "Kevin Lingfeng Li"
format:
    pdf:
        toc: true
        toc-depth: 2
        documentclass: report
        papersize: A4
        geometry:
            - width=165mm
            - height=245mm
            - top=27mm
        number-sections: true
        number-depth: 1
        top-level-division: part
        linestretch: 1.25
---

## Preface {.unnumbered}

**Political Economics** is the use of economic models and approaches to study politics. More specifically, it is the use of microeconomic-style rational choice models and game theory to study political behaviour and institutions, and how that impacts political outcomes. These models and predictions are then validated with real-world data using econometric techniques.

This book is the first volume in a sequence on **Political Economics**.

-   [Microeconomic Theory for Political Analysis](https://kevinli03.github.io/politicaleconomy/1.pdf) (this book) introduces key concepts microeconomic theory and game theory that form the foundations of economic models of politics.

-   [Econometrics for Political Analysis](https://kevinli03.github.io/politicaleconomy/2.pdf) introduces key statistical/econometric methods used to empirically test models and phenomena with real-world data.

-   [Economic Analysis of Politics](https://kevinli03.github.io/politicaleconomy/3.pdf) applies the microeconomic theory and econometric techniques discussed in the previous book to current academic topics.

Furthermore, there is a companion sequence: *Quantitative Methods*, which discussed mathematical and statistical techniques useful for the study of Political Economics.

This first book focuses on introducing the fundamentals of microeconomics, such as preference and utility theory, as well as introduce the essentials of game theory and formal models. Topics covered include preferences, static games, dynamic games, and bayesian games. Along the way, models relevant to political situations will be used as examples.

This course requires, at a minimum, an understanding of single variable calculus and probability theory, up to the level of [Volume I](https://kevinli03.github.io/math/1.pdf) of the Quantitative Methods Sequence. Ideas and games presented in this book will utilise differential calculus and Bayes' theorem extensively. Furthermore, it is recommended that one has a baseline understanding of multivariate calculus and some experience with proofs, although this is not essential.

It is also important to note that economics is a very notation-heavy discipline. The beginning sections introduce this notation, and it is essential to quickly pick up this notation to succeed.

## Introductory Microeconomic Theory

Notation note: $\in$ means *in* or *belongs to*, $:$ means *such that*, $\forall$ means *for all*, $\mathbb{R}$ indicates the set of all real numbers, $\mathbb{Z}$ indicates the set of all integers.

### Agents and Preference Relations

**Agents** are anything that makes decisions. They can be people, firms, political parties, candidates, etc., anything that can make decisions.

Let us define $X$ as a set of **alternative outcomes** that agents can achieve. [Alternatives are both mutually exclusive and exhaustive]{.underline}:

-   Mutually exclusive means that ending up with one outcome, means you cannot end up with any outcome. For example, on a math test, you have the potential outcomes of any score between 0 and 100. If you end up with a 95, you cannot at the same time, end up with an 84.

-   Exhaustive means that every possible outcome of a situation is included in set $X$. For example, on a math test (assuming no extra credit), the set of all possible outcomes is $X = \{ x : x \in \mathbb{R}; 0 ≤ x ≤ 100 \}$. Or in more intuitive terms, set $X$ contains all real numbers between 0 and 100 (we are assuming you can get decimal percentages).

::: callout-tip
## Key Definition

$\succsim$ is a **preference relation** over the set of alternatives $X$. It indicates the relationship between two elements within $X$.

 

If $x, y \in X$, and when $x \succsim y$, that means the agent **weakly prefers** alternative $x$ to $y$. Weakly preferences means that an agent either prefers alternative $x$ to $y$, or is indifferent between $x$ and $y$. However, they never prefer $y$ to $x$.
:::

Other preference relations include:

-   **Strict Preference**: When $x \succ y$, that means an agent always prefers $x$ to $y$. i.e. if they are given opportunities to choose between outcomes $x$ and $y$, they will always, 100% of the time, select $x$ over $y$.

-   **Indifference**: When $x \sim y$, that means an agent is indifferent between $x$ and $y$ - they do not have a preference over which outcome they get.

### Rational Preferences and Utility Functions

#### Preferences

We assume that agents have **rational** preferences. Preferences are considered rational if they are both complete and transitive.

**Complete** preferences means that for every two elements $x, y \in X$, either $x \succsim y$ or $y \succsim x$, or both. In more intuitive terms, for every two possible alternatives, agents must either prefer one alternative over another, or be indifferent between the two. They cannot be "unsure" of their preferences (note: unsure is not the same as indifferent).

-   For example, if set $X$ is all the possible outcomes of my math test, I must be able to select any two scores that are possible, and be able to compare them. I prefer outcome 100 to outcome 95 on my test. Maybe I am indifferent between 92 and 91. However, when asked, I am never "not sure" between any two outcomes.

**Transitive** preferences means that for three elements $x, y, z \in X$, if $x \succsim y$, and $y \succsim z$, then $x \succsim z$. A simple example is that - if I prefer apples to oranges, and I prefer oranges to watermelon, then, I should prefer apples to watermelon. This might seem arbitrary with fruits, however, with numbers, it makes more sense. If I prefer a score of 100 compared to 95, and I prefer a score of 95 to 90, then I should prefer 100 to 90.

If individual preferences of an agent are both complete and transitive, then, they are rational. Note the word "individual". As we will cover later, group preferences are often not rational in this sense.

#### Utility Functions

Any rational set of preferences can be represented by a utility function.

::: callout-tip
## Key Definition

A **utility function** is a way to map preferences over $X$ into numerical values. The utility function $u : X \rightarrow \mathbb{R}$ should be such that, for any $x,y \in X$, $u(x) ≥ u(y)$ if and only if $x \succsim y$.

 

More intuitively, this says that the utility function should match our preference relations. If we weakly prefer $x$ to $y$, then our utility function should mirror this, so $u(x) ≥ u(y)$.

 

The same is true for other preference relations: $u(x) > u(y) \Longrightarrow x \succ y$ and $u(x) = u(y) \Longrightarrow x \sim y$.
:::

The utility function allows us to represent the binary preferences (comparisons between two alternatives) in a numeric form, which allows us to compare all outcomes, and is much easier to manipulate mathematically.

Utility functions are **ordinal**: they can be used to rank alternatives, such as if $x \succ y$. However, they cannot be used to tell [how much]{.underline} one prefers $x$ to $y$. In other words, the value $u(x) - u(y)$ has no inherent meaning.

A preference relation can be represented by a utility function only if it is rational (i.e. complete and transitive).

-   If it is not complete, then for some outputs we would not be able to assign utilities, which would break the utility function.

-   If it is not transitive, it cannot be represented in numbers, as numbers are transitive. For example, $5 >4$, and $4>3$, so $5>3$ must be true for numbers. If preferences are not transitive, they cannot be represented by numbers which are bound by transitivity.

### Agent Rationality

Given a set of choices $X$, what is the "best choice" of an individual? This is an important concept, since without considering an agent's best choice, we cannot make any predictions on the likely outcomes of scenarios involving decision making.

::: callout-tip
## Key Definition

We can define the "best choice" as the outcomes included in the **maximal set** of $X$, notated $M( \succsim, X)$, which is defined as:

$$
M(\succsim, X) = \{ x \in X : x \succsim y \space, \space \forall y \in X \}
$$

Or in intuitive terms, the maximal set is the set of all alternatives $x$ in $X$, such that $x$ is weakly preferred over alternative $y$ for every alternative $y$ in $X$.
:::

Or even more simply, basically, when comparing one outcome to all other outcomes, not a single other outcome is preferred over this outcome. If that is the case, add that outcome to the maximal set.

All outcome alternatives included in the maximal set $M (\succsim, X)$ are considered the "best choices" of an individual, since they are always weakly preferred to any other alternative $y \in X$.

If the utility function $u: X \rightarrow \mathbb{R}$ is a utility representation of the preference relations $\succsim$ of an agent on $X$, then the elements of the maximal set are:

$$
M(\succsim, X) = \arg \max\limits_{x \in X} \{ u(x) \}
$$

Or in more intuitive terms, the inputs $x \in X$ that make the utility function $u : X \rightarrow \mathbb{R}$ achieve its maximum value, are the elements of $x$ in the maximal set $M( \succsim, X)$.

-   Intuitively, since the maximal set contains the alternatives that are weakly preferred to all other alternative outcomes, the utility function output of that weakly preferred outcome should be equal or higher than all other utility function outputs for other alternatives.

This course on the microeconomic theory and its applications to political situations is focused on how agents, such as candidates, political parties, government officials, and others, make decisions according to their maximal set, and how these decisions impact political outcomes.

### Introduction to Game Theory

#### Models and Game Theory

A model is a simplified version of reality to help us understand the complex world around us. This is especially useful in the complex world of the social sciences. To simplify reality, models make **assumptions**.

For example, a driving map is a model of the world. Driving maps simplify the world around us - they depict the earth as flat, and do not contain elevation data, terrain data, and so on. However, these simplifcations allow it to perform the task of facilitating navigation very effectively, without overcomplicating things.

**Game Theory** is the study of mathematical models of conflict and cooperation between rational players. The key property of game theory is that [one player's actions, affect another player's outcomes/gains/payoffs]{.underline}.

Game Theory is frequently used in Economics to study competitive interaction between producers, consumers, and other economic entities. It can also be applied to political situations.

Other key properties of Game Theory include:

-   There is **common knowledge** of the rules of the game. This basically means that every player knows that every other player knows the rules of the game.

-   A player will predict what their opponents will do, and will react to their opponents.

-   The optimal decision of a player, depends on their beliefs on what the other players will do.

#### Properties of Games and Preferences

Games are the environment in which strategic interaction between players occurs. For each game, it must consist of:

1.  A set of **players**
2.  For each player, a set of **actions** and **strategies**.
3.  For each player, **preferences** over the outcomes associated with the actions, such that they have an opinion on every possible outcome of the game. We frequently use utility functions to assign numeric "payoffs" to the possible outcomes of each game.

Players will take actions, and they yield some outcomes. The pathway between actions and outcomes is the **environment** - which includes the rules of the game, the other players' strategies, and the other players' beliefs, influence a player's choice of actions.

-   Essentially, the environment is the utility function - how you get from the inputs to the output payoffs.

A player's preferences over the outcomes of games, in game theory, must be both **complete** and **transitive**. We can assign numbers to both cardinal and ordinal preferences (see chapter 1 and utility functions).

#### Types of Games

Game Theory is divided into the study of a few categories of games. Most games are characterised by two factors: the timing of the game, and the availability of information.

The timing of the game determines how players move relative to each other:

-   A **static game** is when all players move "simultaneously". This does not actually mean they have to move at the exact same moment - it simply means that when one player moves, they cannot yet observe how the other player has moved. Thus, the players must anticipate the other players moves.

-   A **dynamic game** is when players move sequentially, in an order. These are also called extensive form games. This means that players can see how their opponents moved, before they choose their move. For example, Chess is a dynamic game.

The availability of information is another distinction between types of games:

-   A game of **complete information** is one where all payoffs are known to all players.

-   A game of **incomplete information** is when some payoffs or some actions are not common knowledge. These games are quite a bit more complex.

We will start off this book by exploring static games of complete information. Then, we will move to dynamic games of complete information. We will finish with more complex games of incomplete information.

### Game Theory Notation

Before we start exploring games and concepts within Game Theory, we must understand some notation that is commonly used.

**Players** of the game are denoted $i = 1,2,...N$.

-   When we say player $i$, we are referring to any specific player in the game.

-   When we say player 1, or player 2..., we are referring to a specific player in the game.

-   $N$ represents the total number of players in a game.

The **actions** of a player $i$ are denoted $a_i$. They are the choices a player can make at any point in the game.

-   So, the actions of player 1 are denoted $a_1$, and so on.

The **strategies** of a player $i$ are denoted $s_i$. The difference between actions and strategies, is that a strategy consists of what a player will do at every possible point in the game. For example, in chess, a strategy would be a planned move in response to every possible move your opponent could ever make.

-   A player's selected strategy, if applicable, is denoted with a star: $s_i^*$

-   All other strategies of a player $i$ that are not selected $s^*_i$ are denoted with an apostrophe (more specifically, a set complement sign): $s'_i$

-   Mixed strategies will be denoted with a $\sigma$ instead of an $s$ (we will discuss this later).

The **strategy profile** (of all players' stratgies) is a vector $s = (s_1, s_2, ..., s_N)$. A strategy profile defines all player's strategies in a game.

-   We can split this vector into 2 different parts. $s_i$ denotes player $i$'s actions, while $s_{-i}$ denotes the action profiles of all other players not player $i$.

**Preferences** are represented by a payoff function $u_i(s_i, s_{-i})$

-   Essentially, $u_i$ is a function with the inputs of player $i$'s strategies $s_i$, and the strategy profile of every other player $s_{-i}$.
-   These utility functions follow the same principles as discussed previously in the chapter.

Now that we have the basic notation down, let us begin learning game theory!

# Static Games of Complete Information

## Pure Strategy Nash Equilibrium

### Dominant Strategy Equilibrium

#### Dominant Strategies

Sometimes, one of the actions available to a player $i$, is always better than any of the other actions available to them, no matter what their opponent decides to do. This is called a **dominant strategy**.

::: callout-tip
## Key Definition

A **dominant strategy**, notated $s_i^D$, is a dominant strategy, if no matter what the opponent does, the payoff is highest for player $i$ when they play $s_i^D$. Mathematically:

$$
u_i(s_i^D, s_{-i}) > u_i (s_i', s_{-i})
$$

Intuitively, the utility of player $i$ choosing their dominant strategy $s_i^D$, is always greater than the utility of player $i$ choosing another strategy $s_i'$, no matter the strategies chosen by the opponents $s_{-i}$.
:::

If player $i$ has a dominant strategy $s_i^D$, then their other strategies $s_i'$ are considered to be **dominated**.

#### Dominant Strategies in Prisoner's Dilemma

::: callout-note
## Prisoner's Dilemma Game

Two suspects are arrested. If they both remain quiet (cooperate with each other), then both will be convicted for minor offences and sentenced to 1 month in jail. If both rat each other out (defect), then both will be sentenced to jail for 8 months. Finally, if one defects but the other does not, then the confessor is immediately released and the other is sentenced to 10 months.
:::

The game in matrix (normal) form is as follows:

|                    | Cooperate (p2) | Defect (p2) |
|--------------------|----------------|-------------|
| **Cooperate (p1)** | -1, -1         | -10, 0      |
| **Defect (p1)**    | 0, -10         | -8, -8      |

Let us look at player 1. What is the best move for player 1? Pretend player 2 plays cooperate. Thus, we can hide the defect column:

|                    | Cooperate (p2) |
|--------------------|----------------|
| **Cooperate (p1)** | -1, -1         |
| **Defect (p1)**    | **0**, -10     |

What is player 1's best strategy? Well, it is to defect, since payoff $0 > -1$. [So, when player 2 picks cooperate, player 1 should pick defect]{.underline}.

Now, pretend player 2 plays defect. Thus, we can hide the cooperate column:

|                    | Defect (p2) |
|--------------------|-------------|
| **Cooperate (p1)** | -10, 0      |
| **Defect (p1)**    | **-8**, -8  |

What is player 1's best strategy? Well, it is to defect, since payoff $-8 > -10$. [So, when player 2 picks defect, player 1 should pick defect]{.underline}.

Thus, player 1's strategy of defect is the strategy that maximises their payoff, regardless of the strategy of player 2. Thus, [player 1's strategy of defect is a dominant strategy]{.underline}. We can do the same thing for player 2. We will find that the Prisoner's Dilemma thus has a dominant strategy for both players - defect.

#### Dominant Strategy Equilibrium

A dominant strategy equilibrium is a solution concept (likely outcome of a game). A dominant strategy equilibrium occurs when all players play dominant strategies.

-   After all, if everyone has a best response to all other strategies of other players, and everyone is playing their best response, that is a very likely outcome of the game.

::: callout-tip
## Key Definition

A strategy profile of all players $S^D = (S^D_1, S^D_2, ..., S^D_N)$ is a **dominant strategy equilibrium**, if for all players $i$, $u_i(S^D_i, s_{-i}) > u_i(s_i',s_{-i})$ for all $s_{-i}$.

 

Intuitively, a strategy profile is a dominant strategy equilibrium, given every single player is playing a dominant strategy.
:::

For example, take the **prisoner's dilemma**. We have already established that for both players, defect is a dominant strategy. [Thus, if both players play defect, that is a dominant strategy equilibrium]{.underline}.

There, at most, can only be one dominant strategy equilibrium in a game. This makes dominant strategy equilibrium a great solution concept for prediction - as there will always only be one solution. However, many games do not have any dominant strategies, and thus, many games do not have a dominant strategy equilibrium. As a result, this solution concept is not possible on a vast majority of games.

### Nash Equilibrium

#### Best Response

A strategy for player $i$ is a best response to another specific strategy played by the other players, if that chosen strategy for player $i$ gives more payoff than any other strategy player $i$ could choose.

-   Essentially, we [hold the other player's strategies constant]{.underline}. Then, we find what player $i$ should play. We do this for every combination of other player's strategies.

::: callout-tip
## Key Definition

The strategy $s_i$ is a **best response** to the opponents strategy $s_{-i}$, if $u_i(s_i, s_{-i})≥ u_i(s_i', s_{-i})$, where $s'_i$ are the other strategy profiles of player $i$ that are not the chosen $s_i$.

 

Intuitively, if we hold fixed other player's strategies, the strategy $s_i$ is a best response for player $i$ if it gives the highest payoff compared to any other strategy player $i$ could choose.
:::

A strategy profile cannot be a best response, if there exists a **profitable deviation**. Essentially, given the opponent plays a certain strategy, if you can switch to a more profitable strategy, then the original strategy is not a best response.

#### Pure Strategy Nash Equilibrium

Nash Equilibrium is a solution concept, and occurs when both players are playing a best response to the other player's chosen strategy.

As we discussed previously, a best response means a player has no profitable deviation. Thus, when both players are playing a best response to each other in a Nash Equilibrium, [neither player has a profitable deviation]{.underline}.

-   Thus, no player can do better by choosing a different strategy. That means the Nash Equilibria is stable: once we enter the equilibria, no one wants to leave it.

::: callout-tip
## Key Definition

A strategy profile $s^*$ is a **Pure Strategy Nash Equilibrium**, when $u_i(s_i^*, s_{-i}^*) ≥ u_i(s_i', s^*_{-i})$ for all $s'_i$ and for all players $i$.

 

Intuitively, a strategy profile is a Nash Equilibrium, when the chosen strategy of player $i$, [given]{.underline} an opponents strategies, yields a higher payoff than any other strategy that player $i$ could choose. That means no player can deviate to another strategy and receive a higher payoff, holding other player's strategies constant.
:::

All Dominant Strategy Equilibria are a subset of Nash Equilibria. This is because dominant strategies are also, by definition, best responses.

Often, there is more than one Nash Equilibria, and we are not sure which solution is the likely outcome of the game. Sometimes, Nash Equilibria do not exist in a game (although this is less frequent than Dominant Strategy Equilibria).

#### Finding Nash Equilibrium

Finding Nash Equilibria involves finding the best responses for both players. For example, take this following game (game of chicken):

|                   | Swerve (p2) | Straight (p2) |
|-------------------|-------------|---------------|
| **Swerve (p1)**   | 0, 0        | -1, 1         |
| **Straight (p1)** | 1, -1       | -9, -9        |

Let us find the best responses of player 1, while fixing player 2's strategies. The best responses are bolded.

|                   | Swerve (p2) | Straight (p2) |
|-------------------|-------------|---------------|
| **Swerve (p1)**   | 0, 0        | **-1**, 1     |
| **Straight (p1)** | **1**, -1   | -9, -9        |

Next, find the best responses of player 2, while fixing player 1's strategies. The best responses are bolded.

|                   | Swerve (p2)   | Straight (p2) |
|-------------------|---------------|---------------|
| **Swerve (p1)**   | 0, 0          | **-1**, **1** |
| **Straight (p1)** | **1**, **-1** | -9, -9        |

We can see that the strategy profiles, where both players are playing best responses, are (Swerve, Straight), and (Straight, Swerve). Thus, these are the two Nash Equilibria.

### Public Goods Contribution Game

Let us introduce a slightly more complex game:

::: callout-note
## Public Goods Contribution Game

Each of $n$ people chooses whether to contribute a fixed amount toward the provision of a public good. The good is provided if and only if at least k people contribute where $2 ≤ k ≤ n$; if it is not provided, contributions are not refunded. Each person ranks outcomes from best to worst as follows:

-   \(i\) any outcome in which the good is provided and she does not contribute

-   \(ii\) any outcome in which the good is provided and she contributes

-   \(iii\) any outcome in which the good is not provided and she does not contribute

-   \(iv\) and outcome in which the good is not provided and she contributes.
:::

What are the Nash Equilibria of this game?

Let us consider that 0 people contribute to the public good. Does any player have any incentive to deviate? All players are playing "not contribute". Player $i$ does not have a profitable deviation to "contribute", since $k≥2$ so the good will not be provided. Thus, deviating to "contribute" would lower player $i$'s payoff from payoff number iii to payoff number iv from above. Thus, [0 people contributing is a Nash Equilibrium]{.underline}, as no player has an incentive to deviate.

Let us now consider that 1 person is contributing to the public good. Does any player have an incentive to deviate? Let us assume player $i$ is the only player that is contributing. Player $i$ does have a profitable deviation given his opponents current strategies, since if he changes to "not contribute", he will increase his payoff from outcome iv to outcome iii.

-   This will be the case for all cases where $k-2$ or less people contribute, since no player's individual action will be able to reach the threshold of the public good, so all players contributing would have an incentive to not contribute. Thus, 1 person, and anything between and including 1 and $k-2$ people contributing, is not a nash equilibrium, since a profitable deviation exists.

What if there are $k-1$ people contributing though? Well, then if player $i$ is not contributing, he has an incentive to deviate to "contribute", as that will reach the threshold $k$ for the provision of the public good, thus boosting their payoff from outcome iii to outcome ii. Thus, $k-1$ players contributing is also not a Nash Equilibrium, since a profitable deviation exists.

Now, let us consider that $k$ people contribute to the public good. Does any player have any incentive to deviate? Let us say player $i$ is already contributing. If they were to deviate to "not contribute", the total number of contributors would fall below $k$, thus moving player $i$ from outcome ii to outcome iii, lowering his payoffs. Let us say player $i$ is not-contributing. if they were to deviate to "contribute", the good is already and still being provided, so they would go from outcome i to outcome ii, lowering their payoffs. Thus, [$k$ players contributing is a Nash Equilibrium]{.underline}, since no player has a profitable deviation.

Finally, there is the scenario that more than $k$ people contribute. Does any player have an incentive to deviate? Let us say player $i$ is already contributing. If they were to switch to "not contribute", the public good would still be provided. They would move from outcome ii to outcome i, increasing their payoffs. Thus, there is no Nash Equilibrium when more than $k$ people contribute, since there is a profitable deviation.

[Thus, there are two Nash Equilibria in this game: at 0 people contributing, and at $k$ people contributing]{.underline}. This game shows how you can analyse more complex games and find Nash Equilibria - just divide the game into scenarios, and look for players with profitable deviations.

### Pareto Efficiency and Focal Points

::: callout-tip
## Key Definition

A **Pareto Efficient** outcome is that, given that outcome, it is impossible to move to any other outcome that makes at least one player better off, [without making anyone else worse off]{.underline}.
:::

For example, let us take the classic prisoner's dilemma game:

|                    | Cooperate (p2) | Defect (p2) |
|--------------------|----------------|-------------|
| **Cooperate (p1)** | -1, -1         | -10, 0      |
| **Defect (p1)**    | 0, -10         | -8, -8      |

The pareto efficient outcomes are (Cooperate, Cooperate), (Cooperate, Defect), and (Defect, Cooperate). All are outcomes where it is impossible to move to another outcome, without making someone worse off.

The opposite is **pareto inefficient** - an outcome where it is possible to make at least one player better off, without making anyone worse off. In the prisoner's dilemma, (Defect, Defect) is pareto inefficient, since we can move to (Cooperate, Cooperate), which makes both players better off, and no one worse off.

::: callout-note
## General Prisoner's Dilemma Game

Any game that has a dominant strategy of defect, with a pareto inefficient nash equilibrium, can be described as a **prisoner's dilemma game**. Thus, the prisoner's dilemma game is used to explain many phenomena, such as cartel competition, training of staff, public goods and environmental governance, market failures, and many other scenarios where individual rationality leads to worse public outcomes.
:::

#### Multiple Nash Equilibrium and Focal Points

We discussed how one of the weaknesses of Nash Equilibrium is the fact that multiple can exist in a single game. This is bad - since we want solution concepts to help us make predictions about outcomes in the world. If we have multiple potential outcomes, which one is going to happen?

In theory, all Nash Equilibria are supposed to be equally likely to occur. However, there are two ways in which one Nash Equilibria may stand above the rest, and be the most likely outcome of the game.

First, [if one Nash Equilibria is Pareto efficient, when the others are not, then that one is likely to be the outcome]{.underline}. Since Pareto Efficient outcomes mean no player can do better without making anyone worse, and pareto-inefficient outcomes mean that at least one player can do better without making anyone worse, it generally makes sense for players to choose the Nash Equilibria that is Pareto Efficient.

Second, is a concept proposed by Schelling: **Focal Points**. Sometimes, some Nash Equilibria are culturally more "notable" and likely than the other Nash Equilibria. For example, take the following game: You want to meet a friend in Paris, but your phones are both dead. If you both choose the same place, then you get a full payoff. if you two choose different places to meet, then neither get any payoff.

In theory, any location in Paris is a Nash Equilibria - since as long as both of you are at the same place, you are getting the optimal outcome. However, culturally, there are some locations in Paris that are more "obvious". For example, many people would probably meet at the Eiffel Tower. Thus, the Eiffel Tower is a focal point - a likely solution to the game, due to cultural reasons.

### Trembling Hand Perfect Equilibrium

Game theory, as we know, assumes players are rational, and play optimal outcomes. However, in no world is every single individual a rational one. Since Game Theory and models is often about predicting likely outcomes, we want to make sure our solution concepts, like Nash Equilibria, will survive even in the real world, where not everyone is rational.

::: callout-tip
## Key Definition

The **Trembling Hand Perfect Equilibrium**, proposed by economist Reinhard Selten, is a way to test the robustness of Nash Equilibria. Essentially, we assume that one player of a game plays the "suboptimal" strategy at a probability of $\epsilon$. Or in other words, they make a "mistake" at probability $\epsilon$, and play the "correct" strategy at probability $1-\epsilon$.
:::

Given one player does this, we see how the other player reacts, and if they still decide to go with the Nash Equilibrium strategy. If the other player decides to still go with the Nash Equilibrium strategy despite the suboptimal strategy of one player, the Nash Equilibrium is robust.

For example, let us take the following game:

|               | Left (p2) | Right (p2) |
|---------------|-----------|------------|
| **Up (p1)**   | 1, 1      | 2, 0       |
| **Down (p1)** | 0, 2      | 2, 2       |

The two Nash Equilibria of the game are (Up, Left), and (Down, Right).

#### Robustness Tests

Let us test the robustness of the (Up, Left) equilibrium. Assume that player 1 might be irrational at probability $\epsilon$ and select "Down". That means they will be rational at probability $1-\epsilon$, and select "Up". Let us call this probability of playing up at $1-\epsilon$ and probability of playing down at $\epsilon$ as the strategy profile $s_1^{\epsilon}$

Let us assume player 2 is still rational. Does (Up, Left) remain a Nash Equilibria? To test this, let us find player 2's utilities for playing "left" and "right", given player 1 does what was listed above. If player 2 still prefers "left", then it is a robust Nash Equilibria.

The expected utility of player 2, when they play left, is defined as $u_2(L, s_1^{\epsilon}) = 1 \times Pr(Up) + 2 \times Pr(Down)$

-   Where $Pr(Up) = 1 - \epsilon$ is the probability player 1 plays up, and $Pr(Down) = \epsilon$ is the probability that player 1 plays down.
-   Plugging in the probabilities, we get: $u_2(L, s_1^{\epsilon})=1(1-\epsilon) + 2 \epsilon = 1 + \epsilon$

The expected utility of player 2, when they play right, is defined as $u_2(R, s_1^{\epsilon}) = 0 \times Pr(Up) + 2 \times Pr(Down)$

-   Where $Pr(Up) = 1 - \epsilon$ is the probability player 1 plays up, and $Pr(Down) = \epsilon$ is the probability that player 1 plays down.
-   Plugging in the probabilities, we get $u_2(R, s_1^{\epsilon}) = 0(1-\epsilon)+2\epsilon = 2\epsilon$

Thus, when player 2 plays left, they expect a utility of $1-\epsilon$, and when the play right, they expect a utility of $2\epsilon$. The Nash Equilibrium (Up, Left) is only true of player 2 plays left, it is only true of $1-\epsilon > 2\epsilon$. Let us solve for $\epsilon$:

$$
1 > 3\epsilon \space \rightarrow \epsilon < 1/3
$$

Thus, the Nash Equilibrium (Up, Left) remains true as long as player 1 is irrational less than $1/3$ of the time. This is usually considered quite robust. We usually assume $\epsilon$ is quite a small value, such as 0.01, or perhaps at most, 0.1. Thus, the (Up, Left) Nash Equilibria is quite robust against irrational play.

We can test the other Nash Equilibrium (Down, Right) with the same parameters:

-   When player 2 plays left, $u_2(L, s_1^{\epsilon}) = 1\epsilon + 2(1-\epsilon) = 2-\epsilon$

-   When player 2 plays right, $u_2(R, s_1^{\epsilon}) = 0\epsilon + 2(1-\epsilon) = 2-2\epsilon$

(Down, Right) is only a Nash Equilibrium when player 2 plays right. Thus, $2-2\epsilon>2-\epsilon$. Let us solve for $\epsilon$:

$$
2 - 2 > -\epsilon + 2\epsilon \space \rightarrow \epsilon < 0
$$

So, (Down, Right) is only a Nash Equilibrium when player 2 is irrational less than 0% of the time, which is impossible. Thus, (Down, Right) is not a robust Nash Equilibrium

## Mixed Strategy Nash Equilibrium

### Mixed Strategies and Expected Utility

#### Mixed Strategies

So far, we have only allowed players to select specific strategies, which are called pure-strategy. Some games do not have Nash Equilibriums with pure-strategies. However, we can introduce mixed strategies - essentially, a strategy where a player mixes between different actions at certain probabilities.

-   For example, if a player has strategies $A$ and $B$, they could mix them by playing $A$ 50% of the time, and $B$ 50% of the time.

-   The Trembling Hand Nash Equilibrium from last chapter is an example of this.

::: callout-tip
## Key Definition

A **mixed strategy** for player $i$ is a probability distribution over their set of strategies. Given player $i$ has a set of strategies for player $\{ s_1, ..., s_m \}$, a mixed strategy is a vector $\sigma_i$, such that:

$$
\sigma_i = (\sigma_i(s_1), ... , \sigma_i (s_m))
$$

Where $\sigma_i(s_k)$ represents the probability of playing a specific strategy $s_k$ within the mixed strategy. So essentially, a mixed strategy is a vector of different probabilities, each probability associated with a strategy.
:::

For example, if player $i$ has strategies $A$ and $B$, $\sigma_i = (0.25, 0.75)$ is a mixed strategy such that player $i$ will play $A$ 25% of the time, and strategy $B$ 75% of the time.

Also, a pure strategy (as we considered before) is just a special type of mixed strategy - where one strategy has probability 1, and all other strategies have probability 0.

Mixed strategies have a few properties:

1.  $\sigma_i(s_k) ≥ 0, \forall s_k \in \{s_1, ..., s_m\}$. Or in other words, the probabilities within the mixed strategy vector cannot be negative (since probability cannot be negative).
2.  $\sum \sigma_1(s_k) = 1$. Or in other words, all the probabilities in the mixed strategy vector should add up to exactly 1.

#### Expected Payoff of Mixed Strategy

The expected payoff of player $i$ playing pure-strategy $s_i$, given the opponent plays a mixed strategy $\sigma_{-i}$ is:

$$
u_i (s_i , \sigma_{-i}) = \sum\limits_{s_{-i}} \left[ \sigma_{-i}(s_i) \times u_i (s_i, s_{-i}) \right]
$$

Or more intuitively, this is an expected utility. We find probability of the opponent playing some strategy, multiplied with my payoff of my fixed strategy plus the opponents chosen strategy. We do this for all strategies within the opponents mixed strategies, and sum them up to get the expected utility.

### Mixed Strategy Nash Equilibrium

A Mixed Strategy Nash Equilibrium is another solution concept we will introduce.

::: callout-tip
## Key Definition

A mixed strategy profile $\sigma^*$ is a **Mixed Strategy Nash Equilibrium**, if $\sigma_i^*$ is a best response to $\sigma_{-i}^*$ for all players $i \in N$. This is the exact same definition as Nash Equilibrium, just with mixed strategy profiles instead of best responses.
:::

A pure-strategy nash equilibrium (with no mixing) is actually a special type of mixed strategy nash equilibrium - just that one strategy has probability 1, and all the other strategies have probability 0.

An important reason why we introduce Mixed Strategy Nash Equilibriums, is that it has been mathematically proven that [any non-cooperative game with a finite set of actions has a Nash Equilibrium]{.underline}.

An important proposition about mixed strategies is that in a mixed strategy nash equilibrium, [if a player's mixed strategy has two (or more) actions that have non-zero probabilities, they must be indifferent between the two actions]{.underline}.

-   For example, if player $i$ is mixing with different probabilities between actions $A$ and $B$, such that $\sigma_i(A), \sigma_i(B) > 0$, they must be indifferent between them.

-   Why? Well if you are not indifferent between $A$ and $B$, then you would just play the strategy you prefer instead of mixing!

### Finding Mixed Strategy Nash Equilibria

Now that we know what a Mixed Strategy Nash Equilibria is, how do we find all of them in a game?

This is best explained in an example. But let us give a brief overview of the process.

1.  Find all pure-strategy Nash Equilibria (as we have done in previous chapters)
2.  If there are any strategies that are **strictly dominated**, then eliminate those strategies. This is because strictly dominated strategies are never indifferent with other strategies, so they cannot be a part of mixed strategy equilibria.
3.  Find Mixed Strategy Nash Equilibria (see example below). We do this by finding the probabilities of the mixed strategy vectors, that are needed to make players indifferent between their strategies within the mix (since mixed strategies imply indifference as discussed previously).

#### Example

Take the following game:

|       |    $A_2$     |    $B_2$     |  $C_2$   |
|-------|:------------:|:------------:|:--------:|
| $A_1$ |     0, 0     | **2**, **3** | **7**, 0 |
| $B_1$ | **3**, **2** |     0, 0     |   0, 0   |
| $C_1$ |   0, **7**   |     0, 0     |   6, 6   |

We can quickly see the pure-strategy Nash Equilibria are $(A_1, B_2)$ and $(B_1, A_2)$.

Now, we can eliminate strategies $C_1$ and $C_2$ since they are strictly dominated - players 1 and 2 will never prefer that strategy over others. Thus, they will not be in the mixed strategy.

|       |    $A_2$     |    $B_2$     |
|-------|:------------:|:------------:|
| $A_1$ |     0, 0     | **2**, **3** |
| $B_1$ | **3**, **2** |     0, 0     |

Now, let us find the mixed strategy nash equilibria. Let us define the mixed strategies of each player in terms of $p$ and $q$, then find these probabilities.

-   Player 1: $\sigma_1(A_1) = p$ (probability player 1 plays $A_1$ is p). Thus $\sigma_2(B_1) = 1 - p$. Let us define mixed strategy $\sigma_1 = (\sigma_1(A_1), \sigma_1(B_1))$.

-   Player 2: $\sigma_2(A_2) = q$, thus $\sigma_2(B_2) = 1-q$. Let us define mixed strategy $\sigma_2 = (\sigma_2(A_2), \sigma_2(B_2))$.

What is **player 1's** expected utilities when they choose a specific pure-strategy $A_1$? $$
\begin{split}
u_1(A_1, \sigma_2) & = \sigma_2(A_2) \times u_1(A_1, A_2) + \sigma_2(B_2) \times u_1(A_1, B_2) \\
& = q \times 0 + (1-q) \times 2  = 2-2q
\end{split}
$$

What is **player 1's** expected utilities when they choose a specific pure-strategy $B_1$? $$
\begin{split}
u_1(B_1, \sigma_2) & = \sigma_2(A_2) \times u_1(B_1, A_2) + \sigma_2(B_2) \times u_1(B_1, B_2) \\
& = q \times 3 + (1-q) \times 0  = 3q\\
\end{split}
$$

Since we know player 1 must be indifferent between $A_1$ and $B_1$ for a mixed strategy to exist, let us set the two utilities equal to each other: $$
\begin{split}
u_1(A_1, \sigma_2) & = u_1(B_1, \sigma_2) \\
2 - 2q & = 3q \\
q & = \frac{2}{5}
\end{split}
$$

Now, we do the same for player 2. What is **player 2's** expected utilities when they choose a specific pure-strategy $A_2$? $$
\begin{split}
u_2(\sigma_1, A_2) & = \sigma_1(A_1) \times u_2(A_1, A_2) + \sigma_1(B_1) \times u_2(B_1, A_2) \\
& = p \times 0 + (1-p) \times 2 = 2-2p
\end{split}
$$

What is **player 2's** expected utilities when they choose a specific pure-strategy $B_2$? $$
\begin{split}
u_2(\sigma_1, B_2) & = \sigma_1(A_1) \times u_2(A_1, B_2) + \sigma_1(B_1) \times u_2(B_1, B_2) \\
& = p \times 3 + (1-p) \times 9 = 3p
\end{split}
$$

Since we know player 2 must be indifferent between $A_2$ and $B_2$ for a mixed strategy to exist, let us set the two utilities equal to each other: $$
\begin{split}
u_2(\sigma_1, A_2) & = u_2(\sigma_1, B_2) \\
2 - 2p & = 3p \\
p & = \frac{2}{5}
\end{split}
$$

Thus, we have found $q = p = \frac{2}{5}$. That means $(1-p) = (1-q) = \frac{3}{5}$.

Given $\sigma_1 = (\sigma_1(A_1), \sigma_1(B_1), \sigma_1(C_2))$ and $\sigma_2 = (\sigma_2(A_2), \sigma_2(B_2), \sigma_2(C_2))$, our mixed Nash Equilibria are: $$
(\sigma_1, \sigma_2) = \left( (\frac{2}{5}, \frac{3}{5}, 0), (\frac{2}{5}, \frac{3}{5}, 0)\right)
$$

The final 0 is there because remember, strategy $C_1, C_2$ are strictly dominated so they are played 0% of the time.

We can also write our pure-strategy nash equilibria $(A_1, B_2)$ and $(B_1, A_2)$ as mixed-strategy nash equilibria: $$
(\sigma_1, \sigma_2) = ((1, 0, 0), (0, 1, 0)), \text{ and } ((0, 1, 0), (1, 0, 0)
$$

### Infinitely Many Nash Equilibria

There are also examples where we can have an infinite number of Nash Equilibria. For example, take this following game:

|     |     $L$      |     $R$      |
|-----|:------------:|:------------:|
| $T$ |     0, 1     | **0**, **2** |
| $B$ | **2**, **2** |   **0**, 1   |

There are two pure-strategy Nash Equilibria in this game: $(T, R)$ and $(B, L)$. Let us find the mixed-strategy Nash Equilibria. Let us define the mixed strategies of each player in terms of $p$ and $q$, then find these probabilities.

-   Player 1: $\sigma_1(T) = p$ (probability player 1 plays $T$ is p). Thus $\sigma_2(B) = 1 - p$. Let us define mixed strategy $\sigma_1 = (\sigma_1(T), \sigma_1(B))$.

-   Player 2: $\sigma_2(L) = q$, thus $\sigma_2(R) = 1-q$. Let us define mixed strategy $\sigma_2 = (\sigma_2(L), \sigma_2(R))$.

What is **player 1's** expected utilities when they choose a specific pure-strategy $T$? $$
\begin{split}
u_1(T, \sigma_2) & = \sigma_2(L) \times u_1(T, L) + \sigma_2(R) \times u_1(T, R) \\
& = q \times 0 + (1-q) \times 0  = 0
\end{split}
$$

What is **player 1's** expected utilities when they choose a specific pure-strategy $B$? $$
\begin{split}
u_1(B, \sigma_2) & = \sigma_2(L) \times u_1(B, L) + \sigma_2(R) \times u_1(B, R) \\
& = q \times 2 + (1-q) \times 0  = 2q
\end{split}
$$

Since we know player 1 must be indifferent between $T$ and $B$ for a mixed strategy to exist, let us set the two utilities equal to each other: $$
\begin{split}
u_1(T, \sigma_2) & = u_1(B, \sigma_2) \\
0 & = 2q \\
q & = 0
\end{split}
$$

Essentially, this means that if player 2 plays strategy $L$ at all (even at 0.0000% probability), player 1 will not be indifferent between the strategies. Essentially, this means that player 2 must play $R$ for this to be a Nash Equilibrium. Let us worry about this a little later.

Now, we do the same for player 2. What is **player 2's** expected utilities when they choose a specific pure-strategy $L$? $$
\begin{split}
u_2(\sigma_1, L) & = \sigma_1(T) \times u_2(T, L) + \sigma_1(B) \times u_2(B, L) \\
& = p \times 1 + (1-p) \times 2 = 2-p
\end{split}
$$

What is **player 2's** expected utilities when they choose a specific pure-strategy $R$? $$
\begin{split}
u_2(\sigma_1, R) & = \sigma_1(T) \times u_2(T, R) + \sigma_1(B) \times u_2(B, R) \\
& = p \times 2 + (1-p) \times 1 = 1 + p
\end{split}
$$

Now, things are a bit different. We know player 2 must choose $R$ to make $q=0$ and thus make player 1 indifferent. Thus, we know the utility of $R$ for player 2 should be greater or equal than utility of $B$ for this scenario. or equal\
$$
\begin{split}
u_2(\sigma_1, L) & ≤ u_2(\sigma_1, R) \\
2 - p & ≤ 1 + p \\
p & ≥ \frac{1}{2}
\end{split}
$$

Thus, we actually have infinitely many Nash Equilibriums. Let us define $\sigma_1 = (\sigma_1(T), \sigma_1(B))$, and $\sigma_2 = (\sigma_1(L), \sigma_1(R))$ First, let us list out our pure-strategy ones: $(T, R)$ and $(B, L)$. $$
(\sigma_1, \sigma_2) = ((1, 0), (0, 1)) \text{ and } ((0, 1), (1, 0))
$$

We also have infinitely many mixed strategy nash equilibria: $$
(\sigma_1, \sigma_2) = ( (p, 1-p), (0, 1)), s.t. \space p \in \left[\frac{1}{2}, 1 \right]
$$

Note: $s.t.$ means such that.

## Downsian Model of Electoral Competition

### Downsian Model of Electoral Competition

Have you ever noticed that many similar businesses are often located in the same place? There are often competing petrol stations all around the same intersection. Or multiple fast food or coffee chains in the same place. Or a bunch of Chinese stores concentrated in one small area. Hotelling argued this is no accident - these businesses have incentives to locate here. These locations are Nash Equilibriums of the competitive game between businesses.

The **Downsian Model**, also called the **Median Voter Theory**, applies this same logic to political parties.

::: callout-note
## Downsian Model of Electoral Competition

There are two political parties, who both want to win an election. The only action the two parties can take is to choose where to position their party's policy platform on a left-right spectrum (between -1 and 1). Citizens also have preferences along this left-right spectrum between -1 and 1, with the median voter's position being defined as $m$. Citizens will always vote for the party that is positioned closest to their preference on the left-right spectrum.

The party that obtains the most citizens' votes wins. Indifferent citizens (that are equidistant to both party's positions) will have a 50/50 chance to vote for either party. If the parties tie in terms of votes, they each win the election with a 50/50 chance.
:::

We can formalise this game into a strategic game:

-   There are two players - political parties. Let us label them $A$ and $B$

-   The players actions are to choose a policy position between -1 and 1: $p_i \in [-1, 1]$

-   The objective is to attract the most votes (so 50% or above, since there are 2 parties).

What is the Nash Equilibrium of this game?

First, let us think about how any party would win the election: they need 50% of the votes. By definition, the median voter is in the 50th percentile. Thus, to win at least 50 percent of the votes, you must win the median voter. To win the median voter, you must be closer to the median voter's position $m$, than the other party.

Eventually, the two parties will converge at the median voter's preference $m$. Since you always want to be closer to the median in order to win 50% of the vote, both parties will converge at $m$. [Thus, the Nash Equilibrium of the Downsian Model is strategy profile $(p_A = m, p_B = m)$]{.underline}.

We can check this by checking profitable deviations. With both players playing $m$, they get a payoff of 0.5 chance of winning the election. If either player $i$ moves away from $m$, they automatically lose the election since they are further from the median voter, and get payoff 0. Thus, there is no profitable deviation.

Is the Downsian Model correct? Do parties actually converge at the median? When evaluating models, [we do not evaluate based on their conclusions]{.underline}. To assess any model, we must [critically assess the assumptions on which the model is built on]{.underline}. We will do this in the next few sections.

### Unbounded and Multi-Dimensional Models

In the Downsian Model, we assumed policy preferences are distributed in an interval $[-1, 1]$. However, even without this assumption, the Downsian Model still has a Nash Equilibrium at the median voter position $m$. This is because the median voter is by definition, the 50th percentile. To win a majority, you need to win more than 50%.

In the Downsian Model, we also assumed policy preferences are only in a one-dimensional plain $\mathbb{R}^1$ (the real number line). However, in the real world, policy is often made on many different dimensions, such as a spectrum for environmental policy, immigration policy, social policy, and so on. [When we extend the model beyond one dimension, there is no Nash Equilibrium]{.underline} at all for the parties. The reason for this is that it imitates another game, called the *Budget Allocatio*n or *Divide the Dollar* game:

::: callout-note
## Divide the Dollar Game

There are 3 "regions" $1, 2, 3$ that want budget from the central government, which has only a limited amount of funds. From each region, a politician is elected to represent them. To approve any budget, 2/3 of the politicians need to agree.

Let us represent the total budget as $1$ (100%). The amount of money distributed to each region $q_i$, must meet the criteria: $q_1 + q_2 + q_3 = 1$. Each politician wants the maximum amount of budget for their region.
:::

At first, we might think that a fair distribution between the 3 regions is $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$. However, there is a profitable deviation to this outcome. Take the budget $(\frac{1}{2}, \frac{1}{2}, 0)$ - remember, only 2/3 politicians need to agree to approve a budget. In this new budget, politician 1 increases the budget for their region from $1/3$ to $1/2,$, and politician 2 also increases the budget for their region. Thus, 2/3 politicians agree to the new budget, passing it.

However, there is also a profitable deviation to the budget $(\frac{1}{2}, \frac{1}{2}, 0)$ - $(0, \frac{3}{5}, \frac{2}{5})$. Here, politicians 2 and 3 are increasing their allocation of the budget, and thus, will vote in favor of the new budget.

In fact, for every single budget proposal, there is always an incentive for 2 players to deviate. We can actually demonstrate this with a cyclical example:

[Essentially, there is never a Nash Equilibrium, because there is always an incentive for 2 players to deviate]{.underline}.

We can model a multidimensional Downsian Model in the same way. Each "dimension" of policy, like environmental, defense, social, etc., is a different budget allocation. Each party will always be able to "outflank" the other party by diverting budget away from one issue and giving it to another, making some citizens happier. Thus, there is no Nash Equilibria is the Downsian Model has multiple policy dimensions.

### Other Distributions, Preferences, and Costs

#### Other Distributions of Citizens

In the Downsian Model, we assumed that citizen/voter preferences are uniformly distributed. However, [with any distribution of voter preferences, the median voter theory still holds]{.underline}.

The reason for this is that the median voter position, $m$, by definition, is the 50th percentile - 50% of the citizens are to the right of them, and 50% are to the left of them. Thus, to win any 2-party election, you need to win more than 50% of the votes, and by definition, the 50th percentile must be included in that winning majority.

Note that the median value can change. For example, in a country with very left-leaning citizens, the median position $m$ might not be at 0, it could be $m = -0.5$.

#### Asymmetrical Voter Preferences

In the Downsian Model, we assumed that citizens will vote for the party whose preferences are closest to them. For example, if the citizen had an option of a party to the left within distance 0.2 and a party to the right within distance 0.3, they would prefer the party to the left.

However, some voters do not have symmetrical preferences. For example, a left-wing voter could be uncomfortable with radical-left, so they would actual prefer a candidate 0.2 to the right over a further left candidate 0.1 to the left. This preference would be non-symmetric - i.e. the citizen favours deviations in one direction over another, from their preferred position.

[Even with asymmetric voter preferences, the median voter is still the Nash Equilibrium]{.underline}, as long as the preferences of citizens are single-peaked. Single peaked preference means that they only have one most-preferred policy position, and moving away from this most-preferred policy position from both sides will reduce utility (no need to be symmetric).

#### Costs of Voting and Abstaining Voters

In the Downsian Model, we assumed that there is no cost to voting for citizens, and all citizens vote.

If this assumption is removed, [there is no longer a Nash Equilibrium at the median voter]{.underline}. If both parties are situated at the median, no rational voter will vote if voting is costly - after all, no matter how they vote, the winning party will have the policy platform of the median voter. Thus, their vote is not pivotal to affect the policy actually implemented, and voting (with cost) would simply not be worth it.

Only if parties are somewhat different, will voters be willing to bear the cost of voting to cast a vote. Thus, there is still a converging force towards the median in this scenario (since more towards the median means a higher chance of winning), but the two party's positions would stay far enough apart to incentivise voters to vote.

### Downsian Competition with 3 Parties

In the Downsian Model, we assumed that there are only 2 parties and candidates. [In a 3 party election, there would no longer be a Nash Equilibrium at the median voter position]{.underline}. This is because any party $i$ has a profitable deviation in this scenario.

If party $i$ were to slightly deviate by $\epsilon$ from the median voter, their new position on the spectrum would be $m + \epsilon$. The figure below shows this scenario:

![](figures/1/5.1.png){fig-align="center" width="80%"}

In the figure above, we can see party $i$ that deviates $\epsilon$ from $m$ will win a vote share of $\frac{1}{2} - \frac{1}{2} \epsilon$, while the other two parties combine for $\frac{1}{2} + \frac{1}{2} \epsilon$, which is split between the two parties, so each party has a vote share $\frac{1}{4} + \frac{1}{4}\epsilon$.

Thus, we can write an inequality to see for what deviation $\epsilon$ for player $i$, where player $i$'s vote share will be higher than the other two party's vote share. $$
\begin{split}
\frac{1}{2} - \frac{1}{2} \epsilon & > \frac{1}{4} + \frac{1}{4}\epsilon \\
\frac{1}{4} & > \frac{3}{4} \epsilon \\
\epsilon & < \frac{1}{3}
\end{split}
$$

Thus, when $\epsilon < \frac{1}{3}$, then party $i$ gets the most votes of any party. Since if they did not deviate by $\epsilon$ and stayed at the median, they would have tied, that means party $i$ has a profitable deviation when the deviation $\epsilon < \frac{1}{3}$. Since party $i$ has a profitable deviation, we can conclude that [there is no Nash Equilibrium at the median voter in a 3 party election]{.underline}.

### Policy-Seeking Parties

In the Downsian Model, we assumed that parties only care about winning elections (called rent-seeking behaviour). Thus, they are willing to adopt any policy that will help them win elections.

However, many politicians actually hold strong beliefs over what policies are right and wrong. Thus, it is reasonable to expect that some parties may derive utility from the specific policies that can implement (policy-seeking behaviour). For example, while a socialist candidate may more easily win elections acting as a moderate at the median voter, they might also lose utility because they personally believe strongly in socialist policies.

Let us pretend there are two parties, the *right* party $R$ and the *left* party $L$, who are on some political spectrum in $[-1, 1]$. Let us assume party $R$ prefers the policy position $p_R = 1$ the most, while party $L$ prefers the policy $p_L = -1$ the most.

-   We can represent this in a utility function - where parties get more utility when the policy implemented by the winning party is closer to their preferred position, and get less utility when the policy implemented by the winning party is further from their preferred position.

-   Mathematically, utility of party $R$ is $u_R(p) = -(p-1)^2$, where $p$ is the implemented policy position. This is because as the implemented policy $p$ goes further from 1, the utility falls in the utility function. The peak utility of this function is at policy position $1$.

-   Similarly, utility of party $L$ is $u_L(p) = -(p+1)^2$, where $p$ is the implemented policy position. This function decreases as you go away from policy position $-1$, and has a maximum utility at policy position $-1$.

We can also define $\pi(p_L, p_R)$ as the probability party $L$ wins the election. Thus, we can write out the utility function of party $L$:

$$
u_L(p_L, p_R) = \pi(p_L, p_R) \times -(p_L + 1)^2 + [1 - \pi(p_L, p_R)] \times -(p_R + 1)^2
$$

Let us break this utility function down into its constituent parts to better understand it:

-   The left hand side of the equation, $u_L(p_L, p_R)$, is the utility function of party $L$, given party $L$ plays some position $p_L$, and party $R$ plays some position $p_R$.

-   The first part of the right hand side, $\pi(p_L, p_R) \times -(p_L + 1)^2$, consists of two parts. $\pi(p_L, p_R)$ is the probability party $L$ wins the election. $-(p_L + 1)^2$ is the utility function of party $L$ we created previously, but since party $L$ wins the election, we replace $p$ with $p_L$. These two parts essentially state: given the probability party $L$ wins the election, how does it feel about the own policies it is implementing?

-   The second part of the right hand side, $[1 - \pi(p_L, p_R)] \times -(p_R + 1)^2$, consists of two parts. $[1 - \pi(p_L, p_R)]$ represents the probability that party $R$ wins the election, since $\pi(p_L, p_R)$ is the probability that party $L$ wins the election. $-(p_R + 1)^2$ is the utility function of party $L$ we created previously, but since party $R$ wins the election, we replace $p$ with $p_R$. These two parts essentially state: given the probability party $R$ wins the election, how does party $L$ feel about the policies that party $R$ is implementing.

So essentially, the utility function of player $L$ is a expected utility of the probability of party $L$ winning the election and implementing its own policies, and the probability of party $R$ winning the election and implementing their probabilities.

[Despite this additional complexity with the policy-seeking behaviour of policies, the median voter is still the Nash Equilibrium of this game]{.underline}. This is because while both parties would like to implement non-median policies, if they deviate away from the median, they will let the other party win, and thus have to deal with the other party's policies, which they find even worse. If you win the election, you implement your own policy, and deny the opponent their chance of implementing their policy that you disagree with.

## Further Spatial Models

### Citizen-Candidate Model

The Downsian Model assumes that parties can select any policy position on the spectrum that will help them win the election. However, in reality, this is not the case. Let us take Bernie Sanders - pretend he was in a presidential election. Bernie decides that in order to maximise his chances of winning, he is going to move to the very centre of the political spectrum where the median voter is. Do you think the voters will believe Bernie has suddenly became a centrist? Likely not - they will assume that Bernie is still a far-left candidate, and many will still vote as if Bernie was a far-left candidate, despite his changed position.

Now, it is not about the politician's policy promises on the political spectrum. Instead, voters are voting on the politician's personal identity and personal preferences on the political spectrum.

The Citizen-Candidate Game is a new strategic game to represent this situation:

::: callout-note
## Citizen-Candidate Game

The players of the game are a continuum of citizens along a spectrum, that are both potential voters and candidates. Each citizen has two actions: either remain a voter, or decide to run for office as a candidate. Citizens who remain voters will vote for the candidate closest to their personal preferences.

 

The utility of a player is determined by how close the personal preferences of the candidate is from their own personal preferences. When no candidate enters the race, some status-quo policy $\hat{p}$ is implemented. There is a cost to choosing the action of becoming a candidate, the cost being some number $\delta$.Let us assume the preferred policy of the median citizen is $m=0$, on a spectrum between $[-1, 1]$.
:::

First, let us test if there is a Nash Equilibrium at the median voter $m=0$, where only the median voter decides to become a candidate:

-   The median citizen will only enter as a candidate, if the cost of voting $\delta$ is less than their dislike of the status-quo policy $\hat{p}$. If they do not dislike the status-quo, why bear the cost of becoming a candidate?

-   Let us say that indeed, $\delta ≤ |\hat{p}|$, and the median voter enters the election. If the median voter enters the election, we know that no other voters will enter the race. This is because the median voter will always beat anyone who is not at the median, so other citizens will have no incentive to bear the cost of entering as a candidate $\delta$ if they know they will lose for sure.

-   [Thus, there is a Nash Equilibrium where the median voter runs, given $\delta ≤ |\hat{p}|$]{.underline}, as no other citizen has an incentive to join the election.

Let us now test if there are any equilibrium with 2 candidates deciding to enter the race:

-   First, we know that any pair of candidates running must be equidistant from the median. After all, if one candidate is closer to the median, they will for sure win the election, and thus, the other candidate will have no incentive to join.

-   Thus, we will have two players (let us call them $R$ and $L$), where their positions are $p_R = m +\Delta$ and $p_L = m - \Delta$. We assume $m=0$.

-   If $L$ does not enter the race, then player $R$ will win the race and implement their policy. Same with the reverse.

-   However, $L$ and $R$ will have no incentive to enter the election, if they do not hate each other's policies that much. More specifically, they will not enter the race if their dislike of each other's policy does not exceed the cost of entry $\delta$

-   Thus, when $\delta ≤ 2 \Delta$ (where $2 \Delta$ is the distance between $\Delta$ and $-\Delta$), both player $L$ and $R$ will join the election. No other candidates will join - citizens closer to the median do not dislike either $L$ or $R$ policies enough to endure the cost of joining $\delta$, and any other citizen further from the median will for sure lose to player $L$ and $R$, thus unwilling to bear the cost $\delta$ if they are guaranteed to lose.

-   [Thus, there is an equilibrium with 2 players becoming candidates, where the two players are equidistant distance $\Delta$ from the median $m$, and when the inequality $\delta ≤ 2 \Delta$ is met]{.underline}.

### Public Finance Model

When political parties and candidates run, they often talk about how much taxes they will implement in order to provide government services and public goods.We can represent this situation as a game:

::: callout-note
## Public Finance Model

Citizens are different from each other, with varying incomes $y_i$. This is become some are "talented" and earn a lot, while others make less income. Citizens care about how much they consume privately $c_i$, and also how much they can enjoy the public good $g$.

 

The government provides the public good $g$, but can only pay for this public good through taxes $t$ (we are assuming that there is no borrowing for funding public goods). However, increasing taxes $t$ will be taken from the citizen's income $y_i$, which will reduce the amount they will be able to consume privately $c_i$. What is the optimal amount of tax and public good a political party should promise to win an election?
:::

We can break down the game further and formalise it as follows:

-   The government provides a public good $g≥0$, financed by taxes $t \in [0, 1]$

-   The government can only spend money on the public good, and cannot raise money in any other ways than taxes. Thus, $ty_1 + ty_2 + ... + ty_n = nt\bar{y} = g$. More simply, taxes raised is the tax rate times one's individual income, and the aggregate tax collected from everyone is the tax rate, times the average income, times the number of individuals. That is equal to the amount spent on the public good $g$.

-   Finally, we assume the mean of income $E[y_i] = \bar{y}$ is more than the median of income $y_m$, since almost every distribution of income in the world is right-skewed.

The utility of any citizen $i$ is $u_i = c_i + H(g)$, where $c_i$ is the private consumption of the individual (income after taxes), and $H(g)$ is the utility derived from the public good.

-   Since $c_i$ is private consumption, which is income after taxes, we can define it as a function of taxes and individual income: $c_i = (1-t)y_i$, or essentially, all the income left over after taxes.

-   We will assume $H(g)$, the utility derived from the public good, has [decreasing marginal utility]{.underline}. This means that more $g$ will always yield a higher utility, however, with each additional $g$, the gain in utility is smaller.

#### Finding Nash Equilibrium

Now the question is, what is each individual citizen's preferred amount of public good $g$? Well, we can solve for this. Recall that utility of any citizen is $u_i = c_i + H(g)$. We also know that $c_i = (1-t)y_i$. Let us substitute $c_i$ into the utility function: $$
\begin{split}
& u_i = c-I + H(g) \\
& u_i = (1-t)y_i + H(g)
\end{split}
$$

Next, recall that earlier, we determined that $nt\bar{y} = g$, or essentially, aggregate tax income equals public good provision. We can solve for $t$, to get $t = \frac{g}{n \bar{y}}$. We can plug in that $t$ into our utility function: $$
\begin{split}
& u_i = (1-t)y_i + H(g) \\
& u_i = \left( 1 - \frac{g}{n \bar{y}} \right)y_i + H(g)
\end{split}
$$

Now, notice how we only have one variable left in this equation, $g$, which is good, since we are interested in the citizen's preferred amount of $g$. Let us rewrite the function as a function of $g$:

$$
u_i(g) = \left( 1 - \frac{g}{n \bar{y}} \right)y_i + H(g)
$$

Now, what is each citizen's preferred $g$? Well naturally, it is the amount of $g$ that maximises their utility function. How do we find maximums? By taking the derivative, and setting the derivative equal to 0: $$
\begin{split}
& u_i(g) = \left( 1 - \frac{g}{n \bar{y}} \right)y_i + H(g) \\
& u_i(g) = y_i -\frac{y_i}{n \bar{y}} g + H(g) \\
& u_i'(g) = -\frac{y_i}{n \bar{y}} + H'(g)
\end{split}
$$

Set the derivative equal to 0: $$
\begin{split}
& 0 = -\frac{y_i}{n \bar{y}} + H'(g) \\
& H'(g) = \frac{y_i}{n \bar{y}}
\end{split}
$$

What does this equation tell us? First, we know that $H(g)$ had decreasing marginal utility, which means $H'(g)$ must be decreasing as $g$ increases (see blue line below). We also know that when income $y_i$ is high, $H'(g)$ is high as well. When $y_i$ is low, $H'(g)$ is low.

![](figures/1/5.2.png){fig-align="center" width="30%"}

Thus, we can see, when $y_i$ is high $y^H$ (which means $H'(g)$ is high), the corresponding $g$ is quite small. When $y_i$ is low $y^L$ (which means $H'(g)$ is low), the corresponding $g$ is quite large. This tells us that richer individuals prefer smaller $g$ (less public good, which also implies lower taxes), which poorer individuals prefer larger $g$ (more public good, which also implies higher taxes).

Now, we can model these preferences in a Downsian Game. Two parties $A$ and $B$ compete on the policy position of size of government, choosing positions $p_A$ and $p_B$ on the amount of public good provision (and rate of tax). The party who wins a majority of the votes implements the public good policy that have chosen. Thus, the median voter's preferences, given their income $y_m$, is the outcome of the game:

$$
H'(g) = \frac{y_i}{n \bar{y}} = \frac{y_m}{n \bar{y}}
$$

Remember, lower $g$ means higher $H'(g)$. Thus, a more skewed income distribution with a few very very rich people, which would mean a smaller $y_m$ compared to $\bar{y}$, would mean a smaller $H'(g)$ and thus larger $g$. This should mean that in a 2-party democracy, we should see a larger government that provides more public goods.

A richer country, thus with a higher average income $\bar{y}$, would mean smaller $H'(g)$ and thus larger $g$. Thus, a richer country should also have a larger government.

### Valence Politics Model

So far, we have focused on voters voting on policy. What about voters voting on competence? This is called a Downsian Model with valence.

To simplify this model, let us assume that there are only 3 policy positions in our policy space: $\{-1, 0, 1 \}$ - corresponding to left wing, centrist, and right wing. Voters preferred policies are also distirbuted between these three positions, but we will not define the distribution it takes (could be uniform, skewed, anything).

There are two parties, $L$ and $R$ who want to win the election. However, party $L$ is considered more "competent" by voters, so if party $L$ wins, they get extra payoff of $\delta \in (0, 1)$. We can define voter utility as:

$$
u_i(p) = -|p-p_i| + i(p_R, p_L) \times \delta
$$

Where $p$ is the winning party's policy position, $p_i$ is the voter's preferred policy position, $i(p_R, p_L)$ is a function where win party $L$ wins, $i(p_R, p_L) = 1$, and when party $R$ wins, the $i(p_R, p_L) = 0$.

Essentially, the first part of the equation $-|p-p_i|$ represents the distance between the voter's preference and the winning party's preference, and the second part $i(p_R, p_L) \times \delta$ only applies $\delta$ when party $L$ wins, and equals 0 when party $R$ wins.

Importantly, the two parties do not know the exact location of the median voter. They only know that the median is at $-1$ with probability $\alpha$, located at $1$ with probability $\alpha$, and located at 0 with probability $1-2\alpha$. Essentially, $\alpha \in (0, 1/2)$ captures the polarization of the electorate.

This model basically says that valence/competence does not supersede policy, but when voters are indifferent between the two parties' policies, they will always prefer the more competent candidate.

#### Finding Nash Equilibrium

In this model, party $L$ wants to copy party $R$'s platform, since party $L$ is advantaged by $\delta$, so if both parties end with the same policy, party $L$ will always win. We can represent this game in a payoff matrix:

|  |  |  |  |
|------------------|:----------------:|:----------------:|:----------------:|
|  | $p_R = -1$ | $p_R = 0$ | $p_R = 1$ |
| $p_L = -1$ | $(1, 0)$ | $(\alpha, 1 - \alpha)$ | $(1 - \alpha, \alpha)$ |
| $p_L = 0$ | $(1- \alpha, \alpha)$ | $(1, 0)$ | $(1 - \alpha, \alpha)$ |
| $p_L = 1$ | $(1 - \alpha, \alpha)$ | $(\alpha, 1 - \alpha)$ | $(1, 0)$ |

There are no pure strategy nash equilibria. Let us look at party $L$'s best responses. Let us define $\sigma_R(p_R = 0) = q$, and $\sigma_R(p_R = -1) = \sigma_R(p_R = 1) = \frac{1-q}{2}$.

$$
\begin{split}
u_L(p_L = -1, \sigma_R) & = \frac{1-q}{2}(1) + q(\alpha) + \frac{1-q}{2}(1-\alpha) \\
& = \frac{1-q}{2} + q\alpha + \frac{1-q}{2} - \frac{\alpha(1-q)}{2} \\
& = 1-q+q\alpha - \frac{\alpha}{2} + \frac{q\alpha}{2} \\
& = 1-q + \frac{3q\alpha}{2} - \frac{\alpha}{2} \\
u_L(p_L = 0, \sigma_R) & = \frac{1-q}{2}(1-\alpha) + q(1) + \frac{1-q}{2}(1-\alpha) \\
& = (1-q)(1-\alpha) + q \\
& = 1 - \alpha - q + q\alpha + q \\
& = 1-\alpha+q\alpha
\end{split}
$$

We know that for mixed strategy, player $L$ must be indifferent, thus:

$$
\begin{split}
u_L(p_L = -1, \sigma_R) & = u_L(p_L = 0, \sigma_R) \\
1-q+ \frac{3q\alpha}{2} - \frac{\alpha}{2} & = 1- \alpha + q\alpha \\
2 - 2q + 3q\alpha - \alpha & = 2 - 2\alpha + 2q\alpha \\
-2q + q\alpha & = - \alpha\\
-q(2 -\alpha) & = - \alpha \\
q = \frac{\alpha}{2-\alpha}
\end{split}
$$

We can do the same for player $R$, which will yield us $\sigma_L(p_L = 0) = p = \frac{2-3\alpha}{2-\alpha}$.

What does this tell use? Well, we can see that if $\alpha \in (0, 1/2)$ consistent between the two players (it has to be), then $\sigma_R(p_R = 0) > \sigma_L(p_L = 0)$. Or more intuitively, this model predicts that the less "competent" candidate will optimally play the centrist policy less, and move towards more extreme policies more often.

This makes sense - if the less competent candidate ends up with the same policy position as the more competent candidate, they will lose, so the less competent candidate must differentiate themselves with a more extreme platform. They will have to hope that the actual median voter is in those more extreme places (as the parties do not know the median voter).

### Schelling Model Complex Systems

The idea of complex systems is that, even if individuals have quite mild preferences, it can lead to drastic unintended consequences on a societal level.

Schelling introduced this idea with his **model of segregation**. Imagine a society composed of two groups: the greens and the blues. A grid represents the geographical area where these two groups live.

Each person is concerned about their neighbourhood - which are the 8 grid cells that surround their cell on the grid. Members of both groups have mild preferences - they are happy to be a minority in their neighbourhood, so long as they have at least 1/3 of their neighbours from the same group. If this condition is not met, they will move to another cell on the grid which fits this condition.

We can randomly place greens and blues on a grid, and check each preference, and move the individuals when their preferences are not met. Every time one player moves, they not only affect the balance of the groups in neighbourhood they move into, but also the neighbourhood they left.

If we continue to run this game until every individual has their preference met, we will be met with a quite shocking result - almost complete segregation of the greens and blues. Schilling created this model to show how relatively moderate preferences (players willing to be minority in their neighbourhood, as long as 1/3 is their own group), can result in drastic societal outcomes.

Schilling generalised this idea into his concept of a complex system.

::: callout-tip
## Key Definition

A **complex system** consists of these elements:

1.  The system is composed of a set of elements/parts, such as inhabitants of a society.
2.  These parts must interact with each other according to well-defined rules.
3.  Following these rules, the system-level outcome has very different properties to those possessed by individual parts. In other words, mild individual preferences lead to drastic societal outcomes.
4.  These drastic outcomes are a result of self-organisation according to the rules of the system. This is because of the **tipping process**: how one individual's actions affect others.
5.  These drastic outcomes are novel: they are hard to predict from knowledge of the properties of the system's individual parts.
:::

Complex systems tell us that we need to be careful learning about individual preferences from only the collective outcome - since the collective outcome can be very different from the individual preferences.

# Dynamic Games

## Subgame Perfect Nash Equilibrium

## Legislative Bargaining Models

## Elections as Incentive Devices

# Bayesian Games

## Dynamic Games of Incomplete Information

## Perfect Bayesian Equilibrium

## Signalling Games

# Advanced Games from Economics

## Cournot Competition

## Stackleberg Competition